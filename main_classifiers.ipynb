{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "####################################################\n",
    "# Load the data\n",
    "df = pd.read_csv(\"n/full_data_flightdelay.csv.xz\", compression='xz')\n",
    "# df = pd.read_csv(\"test.csv.xz\", compression='xz')\n",
    "#print(df.head())\n",
    "\n",
    "# take a random sample of 1000 rows\n",
    "df = df.sample(n=10000)\n",
    "\n",
    "ontime = df[df['DEP_DEL15'] == 0]\n",
    "delayed = df[df['DEP_DEL15'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING\n",
    "# encode the categorical data\n",
    "le = LabelEncoder()\n",
    "\n",
    "def clean_labels_encoder(list_of_labels, df):\n",
    "    for label in list_of_labels:\n",
    "        df[label] = le.fit_transform(df[label])\n",
    "    return df\n",
    "\n",
    "# clean the labels\n",
    "list_of_labels = ['CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT', 'DEP_TIME_BLK']\n",
    "df = clean_labels_encoder(list_of_labels, df)\n",
    "\n",
    "# Drop the columns that are not needed\n",
    "# df = df.drop(['CARRIER_HISTORICAL', 'DEP_AIRPORT_HIST', 'DAY_HISTORICAL',\n",
    "#        'DEP_BLOCK_HIST'], axis=1)\n",
    "\n",
    "# Fill the missing values\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler\n",
      "Random Forest\n",
      "0.8115\n",
      "[[1608   21]\n",
      " [ 356   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      1629\n",
      "           1       0.42      0.04      0.07       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.62      0.51      0.48      2000\n",
      "weighted avg       0.74      0.81      0.74      2000\n",
      "\n",
      "KNN\n",
      "0.7905\n",
      "[[1546   83]\n",
      " [ 336   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1629\n",
      "           1       0.30      0.09      0.14       371\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.56      0.52      0.51      2000\n",
      "weighted avg       0.72      0.79      0.74      2000\n",
      "\n",
      "SVM\n",
      "0.8145\n",
      "[[1628    1]\n",
      " [ 370    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      1629\n",
      "           1       0.50      0.00      0.01       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.66      0.50      0.45      2000\n",
      "weighted avg       0.76      0.81      0.73      2000\n",
      "\n",
      "LGBM\n",
      "0.8085\n",
      "[[1597   32]\n",
      " [ 351   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      1629\n",
      "           1       0.38      0.05      0.09       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.60      0.52      0.49      2000\n",
      "weighted avg       0.74      0.81      0.74      2000\n",
      "\n",
      "MinMax Scaler\n",
      "Random Forest\n",
      "0.8075\n",
      "[[1600   29]\n",
      " [ 356   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      1629\n",
      "           1       0.34      0.04      0.07       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.58      0.51      0.48      2000\n",
      "weighted avg       0.73      0.81      0.74      2000\n",
      "\n",
      "KNN\n",
      "0.785\n",
      "[[1541   88]\n",
      " [ 342   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1629\n",
      "           1       0.25      0.08      0.12       371\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.53      0.51      0.50      2000\n",
      "weighted avg       0.71      0.79      0.74      2000\n",
      "\n",
      "SVM\n",
      "0.8145\n",
      "[[1629    0]\n",
      " [ 371    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      1629\n",
      "           1       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.41      0.50      0.45      2000\n",
      "weighted avg       0.66      0.81      0.73      2000\n",
      "\n",
      "LGBM\n",
      "0.811\n",
      "[[1600   29]\n",
      " [ 349   22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      1629\n",
      "           1       0.43      0.06      0.10       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.63      0.52      0.50      2000\n",
      "weighted avg       0.75      0.81      0.75      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform Random Forest, KNN, SVM, and LGBM with the scaled data\n",
    "def perform_classification(df):\n",
    "    X = df.drop(['DEP_DEL15'], axis=1)\n",
    "    y = df['DEP_DEL15']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    classifiers = {RandomForestClassifier(): 'Random Forest', \n",
    "               KNeighborsClassifier(n_neighbors=5): 'KNN', \n",
    "               SVC(): 'SVM',\n",
    "               LGBMClassifier(verbose=-1): 'LGBM'}\n",
    "\n",
    "    scalers = {StandardScaler():\"Standard Scaler\", MinMaxScaler(): \"MinMax Scaler\"}\n",
    "    for scaler, name_scaler in scalers.items():\n",
    "        print(name_scaler)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        for clf, name in classifiers.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print(name)\n",
    "            print(accuracy_score(y_test, y_pred))\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            print(classification_report(y_test, y_pred))\n",
    "perform_classification(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler\n",
      "Random Forest\n",
      "0.7865\n",
      "[[1554   75]\n",
      " [ 352   19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1629\n",
      "           1       0.20      0.05      0.08       371\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.51      0.50      0.48      2000\n",
      "weighted avg       0.70      0.79      0.73      2000\n",
      "\n",
      "KNN\n",
      "0.7865\n",
      "[[1553   76]\n",
      " [ 351   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1629\n",
      "           1       0.21      0.05      0.09       371\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.51      0.50      0.48      2000\n",
      "weighted avg       0.70      0.79      0.73      2000\n",
      "\n",
      "SVM\n",
      "0.8145\n",
      "[[1629    0]\n",
      " [ 371    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      1629\n",
      "           1       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.41      0.50      0.45      2000\n",
      "weighted avg       0.66      0.81      0.73      2000\n",
      "\n",
      "LGBM\n",
      "0.813\n",
      "[[1621    8]\n",
      " [ 366    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1629\n",
      "           1       0.38      0.01      0.03       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.60      0.50      0.46      2000\n",
      "weighted avg       0.74      0.81      0.74      2000\n",
      "\n",
      "MinMax Scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.783\n",
      "[[1547   82]\n",
      " [ 352   19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88      1629\n",
      "           1       0.19      0.05      0.08       371\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.50      0.50      0.48      2000\n",
      "weighted avg       0.70      0.78      0.73      2000\n",
      "\n",
      "KNN\n",
      "0.7855\n",
      "[[1551   78]\n",
      " [ 351   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1629\n",
      "           1       0.20      0.05      0.09       371\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.51      0.50      0.48      2000\n",
      "weighted avg       0.70      0.79      0.73      2000\n",
      "\n",
      "SVM\n",
      "0.8145\n",
      "[[1629    0]\n",
      " [ 371    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      1629\n",
      "           1       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.41      0.50      0.45      2000\n",
      "weighted avg       0.66      0.81      0.73      2000\n",
      "\n",
      "LGBM\n",
      "0.813\n",
      "[[1621    8]\n",
      " [ 366    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1629\n",
      "           1       0.38      0.01      0.03       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.60      0.50      0.46      2000\n",
      "weighted avg       0.74      0.81      0.74      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Perform Random Forest, KNN, SVM, and LGBM with the PCA data\n",
    "def perform_classification_pca(df):\n",
    "    X = df.drop(['DEP_DEL15'], axis=1)\n",
    "    y = df['DEP_DEL15']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    classifiers = {RandomForestClassifier(): 'Random Forest', \n",
    "               KNeighborsClassifier(n_neighbors=5): 'KNN', \n",
    "               SVC(): 'SVM',\n",
    "               LGBMClassifier(verbose=-1): 'LGBM'}\n",
    "\n",
    "    scalers = {StandardScaler():\"Standard Scaler\", MinMaxScaler(): \"MinMax Scaler\"}\n",
    "    for scaler, name_scaler in scalers.items():\n",
    "        print(name_scaler)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        pca = PCA(n_components=2)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        for clf, name in classifiers.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print(name)\n",
    "            print(accuracy_score(y_test, y_pred))\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "perform_classification_pca(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler\n",
      "Random Forest\n",
      "0.812\n",
      "[[1614   15]\n",
      " [ 361   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      1629\n",
      "           1       0.40      0.03      0.05       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.61      0.51      0.47      2000\n",
      "weighted avg       0.74      0.81      0.74      2000\n",
      "\n",
      "KNN\n",
      "0.7905\n",
      "[[1546   83]\n",
      " [ 336   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1629\n",
      "           1       0.30      0.09      0.14       371\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.56      0.52      0.51      2000\n",
      "weighted avg       0.72      0.79      0.74      2000\n",
      "\n",
      "SVM\n",
      "0.616\n",
      "[[1049  580]\n",
      " [ 188  183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73      1629\n",
      "           1       0.24      0.49      0.32       371\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.54      0.57      0.53      2000\n",
      "weighted avg       0.74      0.62      0.66      2000\n",
      "\n",
      "LGBM\n",
      "0.6575\n",
      "[[1138  491]\n",
      " [ 194  177]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77      1629\n",
      "           1       0.26      0.48      0.34       371\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.56      0.59      0.55      2000\n",
      "weighted avg       0.75      0.66      0.69      2000\n",
      "\n",
      "MinMax Scaler\n",
      "Random Forest\n",
      "0.8145\n",
      "[[1619   10]\n",
      " [ 361   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      1629\n",
      "           1       0.50      0.03      0.05       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.66      0.51      0.47      2000\n",
      "weighted avg       0.76      0.81      0.74      2000\n",
      "\n",
      "KNN\n",
      "0.785\n",
      "[[1541   88]\n",
      " [ 342   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1629\n",
      "           1       0.25      0.08      0.12       371\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.53      0.51      0.50      2000\n",
      "weighted avg       0.71      0.79      0.74      2000\n",
      "\n",
      "SVM\n",
      "0.5885\n",
      "[[959 670]\n",
      " [153 218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.59      0.70      1629\n",
      "           1       0.25      0.59      0.35       371\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.55      0.59      0.52      2000\n",
      "weighted avg       0.75      0.59      0.63      2000\n",
      "\n",
      "LGBM\n",
      "0.664\n",
      "[[1150  479]\n",
      " [ 193  178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.77      1629\n",
      "           1       0.27      0.48      0.35       371\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.56      0.59      0.56      2000\n",
      "weighted avg       0.75      0.66      0.69      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Random Forest, KNN, SVM, and LGBM with weighted data\n",
    "\n",
    "def perform_classification_weighted(df):\n",
    "    X = df.drop(['DEP_DEL15'], axis=1)\n",
    "    y = df['DEP_DEL15']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    weights = (y_train == 0).sum() / (1.0 * (y_train == 1).sum())\n",
    "    classifiers = {RandomForestClassifier(class_weight={0: 1, 1: weights}): 'Random Forest', \n",
    "               KNeighborsClassifier(n_neighbors=5): 'KNN', \n",
    "               SVC(class_weight={0: 1, 1: weights}): 'SVM',\n",
    "               LGBMClassifier(boosting_type='dart', verbose=-1, \n",
    "                              class_weight={0: 1, 1: weights}, \n",
    "                              random_state=42): 'LGBM'}\n",
    "\n",
    "    scalers = {StandardScaler():\"Standard Scaler\", MinMaxScaler(): \"MinMax Scaler\"}\n",
    "    for scaler, name_scaler in scalers.items():\n",
    "        print(name_scaler)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        for clf, name in classifiers.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print(name)\n",
    "            print(accuracy_score(y_test, y_pred))\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "perform_classification_weighted(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "RFECV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
      "      scoring='neg_mean_squared_error', verbose=1)\n",
      "Optimal number of features 20\n",
      "[ 7 12 13 21 22]\n",
      "Index(['CARRIER_NAME', 'AVG_MONTHLY_PASS_AIRLINE', 'FLT_ATTENDANTS_PER_PASS',\n",
      "       'SNOW', 'SNWD'],\n",
      "      dtype='object')\n",
      "Random Forest\n",
      "0.811\n",
      "[[1610   19]\n",
      " [ 359   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.89      1629\n",
      "           1       0.39      0.03      0.06       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.60      0.51      0.48      2000\n",
      "weighted avg       0.74      0.81      0.74      2000\n",
      "\n",
      "KNN\n",
      "0.7815\n",
      "[[1533   96]\n",
      " [ 341   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      1629\n",
      "           1       0.24      0.08      0.12       371\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.53      0.51      0.50      2000\n",
      "weighted avg       0.71      0.78      0.74      2000\n",
      "\n",
      "SVM\n",
      "0.8145\n",
      "[[1629    0]\n",
      " [ 371    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      1629\n",
      "           1       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.41      0.50      0.45      2000\n",
      "weighted avg       0.66      0.81      0.73      2000\n",
      "\n",
      "LGBM\n",
      "0.69\n",
      "[[1231  398]\n",
      " [ 222  149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80      1629\n",
      "           1       0.27      0.40      0.32       371\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.56      0.58      0.56      2000\n",
      "weighted avg       0.74      0.69      0.71      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fraser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Perform Recursive Feature Elimination\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def perform_rfe(df):\n",
    "    X = df.drop(['DEP_DEL15'], axis=1)\n",
    "    y = df['DEP_DEL15']\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    selector = RFECV(clf, step=1, scoring='neg_mean_squared_error',cv=5, verbose=1, n_jobs=-1)\n",
    "    selector.fit(X, y)\n",
    "    selector.transform(X)\n",
    "    print(selector)\n",
    "    print(\"Optimal number of features {}\".format(selector.n_features_))\n",
    "    print(np.where(selector.support_ == False)[0])\n",
    "    print(X.columns[selector.support_ == False])\n",
    "    X.drop(X.columns[selector.support_ == False], axis=1, inplace=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    weights = (y_train == 0).sum() / (1.0 * (y_train == 1).sum())\n",
    "    classifiers = {RandomForestClassifier(): 'Random Forest', \n",
    "               KNeighborsClassifier(n_neighbors=5): 'KNN', \n",
    "               SVC(): 'SVM',\n",
    "               LGBMClassifier(verbose=-1, class_weight={0: 1, 1: weights}): 'LGBM'}\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    for clf, name in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "perform_rfe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "{'lambda_l1': 1.5, 'lambda_l2': 1, 'min_data_in_leaf': 400, 'num_leaves': 31, 'reg_alpha': 0.1}\n",
      "0.6020408163265306\n",
      "0.6215\n",
      "[[1038  591]\n",
      " [ 166  205]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73      1629\n",
      "           1       0.26      0.55      0.35       371\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.56      0.59      0.54      2000\n",
      "weighted avg       0.75      0.62      0.66      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Hyperparameter tuning on the LGBM model\n",
    "\n",
    "\n",
    "def perform_hyperparameter_tuning(df):\n",
    "    X = df.drop(['DEP_DEL15'], axis=1)\n",
    "    y = df['DEP_DEL15']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    weights = (y_train == 0).sum() / (1.0 * (y_train == 1).sum())\n",
    "    lgbm = LGBMClassifier(boosting_type='dart', verbose=-1, \n",
    "                          class_weight={0: 1, 1: weights}, \n",
    "                          random_state=42)\n",
    "    param_grid = {\n",
    "        'num_leaves': [31, 127],\n",
    "        'reg_alpha': [0.1, 0.5],\n",
    "        'min_data_in_leaf': [30, 50, 100, 300, 400],\n",
    "        'lambda_l1': [0, 1, 1.5],\n",
    "        'lambda_l2': [0, 1],\n",
    "        \n",
    "    }\n",
    "    grid_search = GridSearchCV(lgbm, param_grid, cv=5, verbose=1, n_jobs=-1, scoring='recall')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "perform_hyperparameter_tuning(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
